{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "\n",
    "from data_processing import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = get_training_data()\n",
    "X_testing = get_testing_data()\n",
    "#Unnamed: 0 is the Id of the row, we can drop it\n",
    "X = X.drop('Unnamed: 0', axis=1 )\n",
    "\n",
    "x_testing_id = X_testing['Unnamed: 0']\n",
    "X_testing = X_testing.drop('Unnamed: 0', axis=1 )\n",
    "# Unnamed: 0 is the Id of the row, we can drop it\n",
    "y = y.drop(columns=['Unnamed: 0'])  # If the first column is labeled as 'Unnamed: 0'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of elements :', len(X))\n",
    "print('Number of features :', len(X.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('len(y):', len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values = {}\n",
    "for col in X.columns:\n",
    "    unique_values[col] = X[col].value_counts().shape[0]\n",
    "\n",
    "pd.DataFrame(unique_values, index=['unique value count']).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,25))\n",
    "for i,col in enumerate(['BMI', 'GenHlth', 'MentHlth', 'PhysHlth', 'Age','Education', 'Income']):\n",
    "    plt.subplot(4,2,i+1)\n",
    "    plt.title('Distribution of '+col)\n",
    "    plt.boxplot(x = col, data = X, vert=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['HighBP', 'HighChol', 'CholCheck', 'Smoker', 'Stroke', 'HeartDiseaseorAttack', \n",
    "        'PhysActivity', 'Veggies', 'HvyAlcoholConsump', 'AnyHealthcare', 'NoDocbcCost', 'DiffWalk']\n",
    "\n",
    "def create_plot_pivot(data, x_column):\n",
    "    \"\"\"Create a pivot table for satisfaction versus another rating for easy plotting.\"\"\"\n",
    "    # Merge `X` and `y` to ensure access to 'Diabetes_binary' column for grouping\n",
    "    data_with_target = data.copy()\n",
    "    data_with_target['Diabetes_binary'] = y['Diabetes_binary']\n",
    "    data_with_target['Diabetes_binary'] = data_with_target['Diabetes_binary'].replace({0: 'No Diabetes', 1: 'Diabetes'})\n",
    "    \n",
    "    _df_plot = data_with_target.groupby([x_column, 'Diabetes_binary']).size() \\\n",
    "                   .reset_index().pivot(columns='Diabetes_binary', index=x_column, values=0)\n",
    "    return _df_plot\n",
    "\n",
    "fig, ax = plt.subplots(3, 4, figsize=(20, 20))\n",
    "axe = ax.ravel()\n",
    "c = len(cols)\n",
    "plt.suptitle('Diabetes Distribution by Features', fontsize=20)\n",
    "\n",
    "# Custom colors for the plot\n",
    "custom_colors = {'No Diabetes': 'green', 'Diabetes': 'red'}\n",
    "\n",
    "# Plotting each column in cols\n",
    "for i in range(c):\n",
    "    plot_data = create_plot_pivot(X, cols[i])\n",
    "    plot_data.plot(kind='bar', stacked=True, ax=axe[i], color=[custom_colors[val] for val in plot_data.columns])\n",
    "    axe[i].set_xlabel(cols[i])\n",
    "    \n",
    "    # Adding percentage labels for the \"Diabetes\" (red) part of each bar\n",
    "    for j, (index, row) in enumerate(plot_data.iterrows()):\n",
    "        total = row['No Diabetes'] + row['Diabetes']  # Sum of \"No Diabetes\" and \"Diabetes\" counts\n",
    "        if total > 0:\n",
    "            diabetes_percentage = (row['Diabetes'] / total) * 100  # Calculate percentage for Diabetes\n",
    "            axe[i].text(j, row['No Diabetes'] + row['Diabetes'] / 2, \n",
    "                        f\"{diabetes_percentage:.1f}%\", color=\"red\", ha=\"center\", va=\"top\")\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])  # Adjust layout to fit the title\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def normal_probability_plot(data, col):\n",
    "    \"\"\"\n",
    "    Generates a normal probability plot for the given data.\n",
    "    \n",
    "    Parameters:\n",
    "        data (array-like): The data for which to generate the plot.\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Generate a probability plot\n",
    "    stats.probplot(data, dist=\"norm\", plot=plt)\n",
    "    plt.title(\"Normal Probability Plot for \"+ col)\n",
    "    plt.xlabel(\"Theoretical Quantiles\")\n",
    "    plt.ylabel(\"Sample Quantiles\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in X.columns:\n",
    "#     normal_probability_plot(X[col], col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation matrix\n",
    "corr = X.corr()\n",
    "plt.figure(figsize=(30, 15))\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Veggies</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>BMI_Category</th>\n",
       "      <th>Healthy_Diet</th>\n",
       "      <th>Education_Level</th>\n",
       "      <th>Income_Group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.807398</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7.182340</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.018934</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>27.690030</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.576965</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.088206</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24.350989</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.187868</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.916045</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>27.100812</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.088216</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.268324</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30.900910</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>26.942559</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.028891</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   HighBP  HighChol  CholCheck        BMI  Stroke  HeartDiseaseorAttack  \\\n",
       "0       0         0          1  20.807398       0                     0   \n",
       "1       1         1          1  27.690030       0                     0   \n",
       "2       0         0          1  24.350989       0                     0   \n",
       "3       0         0          1  27.100812       0                     0   \n",
       "4       0         1          1  30.900910       0                     0   \n",
       "\n",
       "   PhysActivity  Veggies  AnyHealthcare  GenHlth   PhysHlth  DiffWalk  Sex  \\\n",
       "0             0        1              1        3   7.182340         0    0   \n",
       "1             1        1              1        3   0.576965         0    0   \n",
       "2             1        1              1        1  -0.187868         0    1   \n",
       "3             1        1              1        2  -0.088216         0    1   \n",
       "4             0        1              1        4  26.942559         1    0   \n",
       "\n",
       "         Age  BMI_Category  Healthy_Diet  Education_Level  Income_Group  \n",
       "0   7.018934             0             1                0             1  \n",
       "1  13.088206             2             1                2             2  \n",
       "2   0.916045             0             1                0             0  \n",
       "3   2.268324             2             0                0             0  \n",
       "4   8.028891             1             1                0             1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Look for multicollinearity between the features and remove the features that are unnecessary\n",
    "# we already know the age so age_group is not needed\n",
    "columnsToDrop = ['Age_Group', 'MentHlth', 'HvyAlcoholConsump', 'NoDocbcCost', 'Smoker', 'Fruits', 'Mental_Health_Risk', 'Education', 'Income', 'Heart_Disease_Risk']\n",
    "X = X.drop(columns=columnsToDrop)\n",
    "X = feature_encoding(X)\n",
    "\n",
    "X_testing = X_testing.drop(columns=columnsToDrop)\n",
    "X_testing = feature_encoding(X_testing)\n",
    "\n",
    "X_testing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split validation set and train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validation, y_train, y_validation =  data_splits(X, y) #   split data\n",
    "X_train_scaled, X_validation_scaled, X_testing_Scaled = normalize_features(X_train, X_validation, X_testing) #   normalize data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import gen_batches\n",
    "def predict_in_batches(cls, X, batch_size=100):\n",
    "    \"\"\"\n",
    "    Make predictions for the input data in batches.\n",
    "    \n",
    "    Parameters:\n",
    "        cls (object): The trained classifier model.\n",
    "        X (array-like): The input data to make predictions for.\n",
    "        batch_size (int): The size of each batch.\n",
    "        \n",
    "    Returns:\n",
    "        array-like: The predictions for the input data.\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    \n",
    "    # Generate batches and make predictions for each batch\n",
    "    for batch in gen_batches(len(X), batch_size):\n",
    "        batch_predictions = cls.predict(X[batch])\n",
    "        predictions.append(batch_predictions)\n",
    "    \n",
    "    # Concatenate all batch predictions into a single array\n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "def perform_grid_search(model, X_train_scaled, y_train, params):\n",
    "    print(\"Performing grid search for \", model)\n",
    "    # Define the cross-validation strategy\n",
    "    strat_kfold = StratifiedKFold(n_splits=10) # TODO\n",
    "\n",
    "    # Grid search for the model \n",
    "    #\"f1_macro\": Calculates F1-score per class and takes the average, treating all classes equally.\n",
    "    #\"f1_weighted\": Calculates F1-score per class and takes a weighted average, considering class imbalance.\n",
    "    grid_search = GridSearchCV(model, params, scoring='f1', cv=strat_kfold, n_jobs=10) # n_jobs=10 uses 10 parallel processes. Speeds up the process \n",
    "\n",
    "\n",
    "    if isinstance(model, RandomForestClassifier) or isinstance(model, SVC):\n",
    "        grid_search.fit(X_train_scaled, y_train.values.ravel())\n",
    "    else:\n",
    "        grid_search.fit(X_train, y_train)\n",
    "    best_param = grid_search.best_params_\n",
    "    best_score = grid_search.best_score_ \n",
    "    print(\"Best parameters are:\", best_param)\n",
    "    print(\"Best score is:\", best_score)\n",
    "\n",
    "    # Return the fitted grid search objects\n",
    "    # return grid_search, best_param, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_trainning(model, X_train_scaled, y_train, X_validation_scaled, y_validation):\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_validation_scaled)\n",
    "    validation_f1 = f1_score(y_validation, y_pred)\n",
    "    print(\"Validation f1 score:\", validation_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_summary(y_train, y_train_pred, y_validation, y_validation_pred):\n",
    "    train_f1 = f1_score(y_train, y_train_pred) \n",
    "    validation_f1 = f1_score(y_validation, y_validation_pred) \n",
    "    print(\"Train f1 score:\", train_f1)\n",
    "\n",
    "    print(\"Validation f1 score:\", validation_f1)\n",
    "    print(\"\\nTraining Set Classification Report:\")\n",
    "\n",
    "    print(classification_report(y_train, y_train_pred))\n",
    "\n",
    "    print(\"Training Set Confusion Matrix:\")\n",
    "\n",
    "    print(confusion_matrix(y_train, y_train_pred))\n",
    "\n",
    "    print(\"\\nValidation Set Classification Report:\")\n",
    "\n",
    "    print(classification_report(y_validation, y_validation_pred))\n",
    "\n",
    "    print(\"Validation Set Confusion Matrix:\")\n",
    "\n",
    "    print(confusion_matrix(y_validation, y_validation_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kaggle_submission(model, X_testing_scaled, x_testing_id):\n",
    "    y_pred = model.predict(X_testing_scaled)\n",
    "    y_pred = pd.DataFrame({\n",
    "        'index': x_testing_id , \n",
    "        'Diabetes_binary': y_pred,\n",
    "    })\n",
    "\n",
    "    # Save the predictions to a CSV file\n",
    "    y_pred.to_csv('./y_pred.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search for  RandomForestClassifier(class_weight='balanced', max_depth=20,\n",
      "                       max_leaf_nodes=200, min_samples_leaf=20,\n",
      "                       random_state=42)\n",
      "Best parameters are: {'n_estimators': 500}\n",
      "Best score is: 0.43756226703549733\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False),\n",
       "              estimator=RandomForestClassifier(class_weight='balanced',\n",
       "                                               max_depth=20, max_leaf_nodes=200,\n",
       "                                               min_samples_leaf=20,\n",
       "                                               random_state=42),\n",
       "              n_jobs=10, param_grid={'n_estimators': [100, 200, 300, 400, 500]},\n",
       "              scoring='f1'),\n",
       " {'n_estimators': 500},\n",
       " np.float64(0.43756226703549733))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############### TESTING ####################\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "cls_randomforest = RandomForestClassifier(class_weight='balanced', \n",
    "                                          random_state=42, \n",
    "                                          max_depth=20, \n",
    "                                          max_leaf_nodes=200, \n",
    "                                          min_samples_leaf=20)\n",
    "\n",
    "param_grid_random_forest = {\n",
    "    'n_estimators': [10, 200, 300, 400, 500],\n",
    "    'max_depth': [20, 30],\n",
    "    'bootstrap': [True, False],\n",
    "}\n",
    "perform_grid_search(cls_randomforest, X_train_scaled, y_train, params= param_grid_random_forest)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trainning(cls_randomforest, X_train_scaled, y_train, X_validation_scaled, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = predict_in_batches(cls_randomforest, X_train_scaled)\n",
    "y_validation_pred = predict_in_batches(cls_randomforest, X_validation_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_summary(y_train, y_train_pred, y_validation, y_validation_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search for  LogisticRegression(C=5, class_weight='balanced', max_iter=1000, random_state=42)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sidne\\anaconda3\\envs\\algo\\Lib\\site-packages\\sklearn\\utils\\validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are: {'C': 1, 'max_iter': 1000, 'tol': 0.001}\n",
      "Best score is: 0.4377676476845417\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False),\n",
       "              estimator=LogisticRegression(C=5, class_weight='balanced',\n",
       "                                           max_iter=1000, random_state=42),\n",
       "              n_jobs=10,\n",
       "              param_grid={'C': [1, 10], 'max_iter': [1000, 2000, 3000],\n",
       "                          'tol': [0.001, 0.0001, 1e-05]},\n",
       "              scoring='f1'),\n",
       " {'C': 1, 'max_iter': 1000, 'tol': 0.001},\n",
       " np.float64(0.4377676476845417))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_logistic = LogisticRegression(random_state=42, class_weight='balanced', max_iter=1000, dual=False, C=5)\n",
    "param_grid_logistic = {\n",
    "    'max_iter':[1000, 2000, 3000],\n",
    "    'tol': [1e-3, 1e-4, 1e-5],\n",
    "    'C': [0.5, 1, 10],\n",
    "}\n",
    "perform_grid_search(cls_logistic, X_train_scaled, y_train, param_grid_logistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation f1 score: 0.4367933177141693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sidne\\anaconda3\\envs\\algo\\Lib\\site-packages\\sklearn\\utils\\validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "### Use best parameters to train the model\n",
    "cls_logistic = LogisticRegression(random_state=42, class_weight='balanced', max_iter=1000, dual=False, C=1, tol=1e-3)\n",
    "model_trainning(cls_logistic, X_train_scaled, y_train, X_validation_scaled, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation f1 score: 0.4366340668296659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sidne\\anaconda3\\envs\\algo\\Lib\\site-packages\\sklearn\\utils\\validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "model_trainning(cls_logistic, X_train_scaled, y_train, X_validation_scaled, y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search for  XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric='logloss',\n",
      "              feature_types=None, gamma=None, grow_policy=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
      "              n_jobs=None, num_parallel_tree=None, random_state=42, ...)\n"
     ]
    }
   ],
   "source": [
    "# Initialize the XGBoost classifier\n",
    "# booster [default= gbtree ]\n",
    "# Which booster to use. Can be gbtree, gblinear or dart; gbtree and dart use tree based models while gblinear uses linear functions.\n",
    "xgb_model = XGBClassifier(random_state=42, objective='binary:logistic', eval_metric='logloss')\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'booster': ['gbtree', 'gblinear', 'dart'],\n",
    "    'eval_metric': ['logloss', 'error'],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "perform_grid_search(xgb_model, X_train_scaled, y_train, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary of model name and their trained model\n",
    "trained_models = {\n",
    "        'Decision Tree': cls_decision_tree,\n",
    "        'Random Forest': cls_randomforest,\n",
    "        'SVM': cls_svm }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict labels and calculate accuracy and F1score\n",
    "y_train_pred_dict, y_test_pred_dict, evaluation_results = eval_model(trained_models, X_train_scaled, X_validation_scaled, y_train, y_validation)\n",
    "\n",
    "# classification report and calculate confusion matrix\n",
    "report_model(y_train, y_validation, y_train_pred_dict, y_test_pred_dict, trained_models)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "algo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
