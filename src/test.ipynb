{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "\n",
    "from data_processing import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = get_training_data()\n",
    "X_testing = get_testing_data()\n",
    "#Unnamed: 0 is the Id of the row, we can drop it\n",
    "X = X.drop('Unnamed: 0', axis=1 )\n",
    "\n",
    "x_testing_id = X_testing['Unnamed: 0']\n",
    "X_testing = X_testing.drop('Unnamed: 0', axis=1 )\n",
    "# Unnamed: 0 is the Id of the row, we can drop it\n",
    "y = y.drop(columns=['Unnamed: 0'])  # If the first column is labeled as 'Unnamed: 0'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of elements :', len(X))\n",
    "print('Number of features :', len(X.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('len(y):', len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values = {}\n",
    "for col in X.columns:\n",
    "    unique_values[col] = X[col].value_counts().shape[0]\n",
    "\n",
    "pd.DataFrame(unique_values, index=['unique value count']).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,25))\n",
    "for i,col in enumerate(['BMI', 'GenHlth', 'MentHlth', 'PhysHlth', 'Age','Education', 'Income']):\n",
    "    plt.subplot(4,2,i+1)\n",
    "    plt.title('Distribution of '+col)\n",
    "    plt.boxplot(x = col, data = X, vert=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['HighBP', 'HighChol', 'CholCheck', 'Smoker', 'Stroke', 'HeartDiseaseorAttack', \n",
    "        'PhysActivity', 'Veggies', 'HvyAlcoholConsump', 'AnyHealthcare', 'NoDocbcCost', 'DiffWalk']\n",
    "\n",
    "def create_plot_pivot(data, x_column):\n",
    "    \"\"\"Create a pivot table for satisfaction versus another rating for easy plotting.\"\"\"\n",
    "    # Merge `X` and `y` to ensure access to 'Diabetes_binary' column for grouping\n",
    "    data_with_target = data.copy()\n",
    "    data_with_target['Diabetes_binary'] = y['Diabetes_binary']\n",
    "    data_with_target['Diabetes_binary'] = data_with_target['Diabetes_binary'].replace({0: 'No Diabetes', 1: 'Diabetes'})\n",
    "    \n",
    "    _df_plot = data_with_target.groupby([x_column, 'Diabetes_binary']).size() \\\n",
    "                   .reset_index().pivot(columns='Diabetes_binary', index=x_column, values=0)\n",
    "    return _df_plot\n",
    "\n",
    "fig, ax = plt.subplots(3, 4, figsize=(20, 20))\n",
    "axe = ax.ravel()\n",
    "c = len(cols)\n",
    "plt.suptitle('Diabetes Distribution by Features', fontsize=20)\n",
    "\n",
    "# Custom colors for the plot\n",
    "custom_colors = {'No Diabetes': 'green', 'Diabetes': 'red'}\n",
    "\n",
    "# Plotting each column in cols\n",
    "for i in range(c):\n",
    "    plot_data = create_plot_pivot(X, cols[i])\n",
    "    plot_data.plot(kind='bar', stacked=True, ax=axe[i], color=[custom_colors[val] for val in plot_data.columns])\n",
    "    axe[i].set_xlabel(cols[i])\n",
    "    \n",
    "    # Adding percentage labels for the \"Diabetes\" (red) part of each bar\n",
    "    for j, (index, row) in enumerate(plot_data.iterrows()):\n",
    "        total = row['No Diabetes'] + row['Diabetes']  # Sum of \"No Diabetes\" and \"Diabetes\" counts\n",
    "        if total > 0:\n",
    "            diabetes_percentage = (row['Diabetes'] / total) * 100  # Calculate percentage for Diabetes\n",
    "            axe[i].text(j, row['No Diabetes'] + row['Diabetes'] / 2, \n",
    "                        f\"{diabetes_percentage:.1f}%\", color=\"red\", ha=\"center\", va=\"top\")\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])  # Adjust layout to fit the title\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def normal_probability_plot(data, col):\n",
    "    \"\"\"\n",
    "    Generates a normal probability plot for the given data.\n",
    "    \n",
    "    Parameters:\n",
    "        data (array-like): The data for which to generate the plot.\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Generate a probability plot\n",
    "    stats.probplot(data, dist=\"norm\", plot=plt)\n",
    "    plt.title(\"Normal Probability Plot for \"+ col)\n",
    "    plt.xlabel(\"Theoretical Quantiles\")\n",
    "    plt.ylabel(\"Sample Quantiles\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in X.columns:\n",
    "#     normal_probability_plot(X[col], col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation matrix\n",
    "corr = X.corr()\n",
    "plt.figure(figsize=(30, 15))\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Veggies</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>BMI_Category</th>\n",
       "      <th>Healthy_Diet</th>\n",
       "      <th>Education_Level</th>\n",
       "      <th>Income_Group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.807398</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7.182340</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.018934</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>27.690030</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.576965</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.088206</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24.350989</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.187868</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.916045</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>27.100812</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.088216</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.268324</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30.900910</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>26.942559</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.028891</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   HighBP  HighChol  CholCheck        BMI  Stroke  HeartDiseaseorAttack  \\\n",
       "0       0         0          1  20.807398       0                     0   \n",
       "1       1         1          1  27.690030       0                     0   \n",
       "2       0         0          1  24.350989       0                     0   \n",
       "3       0         0          1  27.100812       0                     0   \n",
       "4       0         1          1  30.900910       0                     0   \n",
       "\n",
       "   PhysActivity  Veggies  AnyHealthcare  GenHlth   PhysHlth  DiffWalk  Sex  \\\n",
       "0             0        1              1        3   7.182340         0    0   \n",
       "1             1        1              1        3   0.576965         0    0   \n",
       "2             1        1              1        1  -0.187868         0    1   \n",
       "3             1        1              1        2  -0.088216         0    1   \n",
       "4             0        1              1        4  26.942559         1    0   \n",
       "\n",
       "         Age  BMI_Category  Healthy_Diet  Education_Level  Income_Group  \n",
       "0   7.018934             0             1                0             1  \n",
       "1  13.088206             2             1                2             2  \n",
       "2   0.916045             0             1                0             0  \n",
       "3   2.268324             2             0                0             0  \n",
       "4   8.028891             1             1                0             1  "
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Look for multicollinearity between the features and remove the features that are unnecessary\n",
    "# we already know the age so age_group is not needed\n",
    "columnsToDrop = ['Age_Group', 'MentHlth', 'HvyAlcoholConsump', 'NoDocbcCost', 'Smoker', 'Fruits', 'Mental_Health_Risk', 'Education', 'Income', 'Heart_Disease_Risk']\n",
    "X = X.drop(columns=columnsToDrop)\n",
    "X = feature_encoding(X)\n",
    "\n",
    "X_testing = X_testing.drop(columns=columnsToDrop)\n",
    "X_testing = feature_encoding(X_testing)\n",
    "\n",
    "X_testing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split validation set and train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training import *\n",
    "is_equal_classes = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic splits of the data\n",
    "X_train, X_validation, y_train, y_validation =  data_splits(X, y) #   split data\n",
    "is_equal_classes = False\n",
    "X_train_scaled, X_validation_scaled, X_testing_Scaled = normalize_features(X_train, X_validation, X_testing) #   normalize data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equal classes splits of the data\n",
    "X_train, X_validation, y_train, y_validation =  data_splits_equal_classes(X, y) #   split data into equal classes. Meaning there is as many diabetes as non diabetes. But we remove some data\n",
    "is_equal_classes = True\n",
    "X_train_scaled, X_validation_scaled, X_testing_Scaled = normalize_features(X_train, X_validation, X_testing) #   normalize data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import gen_batches\n",
    "def predict_in_batches(cls, X, batch_size=100):\n",
    "    \"\"\"\n",
    "    Make predictions for the input data in batches.\n",
    "    \n",
    "    Parameters:\n",
    "        cls (object): The trained classifier model.\n",
    "        X (array-like): The input data to make predictions for.\n",
    "        batch_size (int): The size of each batch.\n",
    "        \n",
    "    Returns:\n",
    "        array-like: The predictions for the input data.\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    \n",
    "    # Generate batches and make predictions for each batch\n",
    "    for batch in gen_batches(len(X), batch_size):\n",
    "        batch_predictions = cls.predict(X[batch])\n",
    "        predictions.append(batch_predictions)\n",
    "    \n",
    "    # Concatenate all batch predictions into a single array\n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "def perform_grid_search(model, X_train_scaled, y_train, params):\n",
    "    print(\"Performing grid search for \", model)\n",
    "    # Define the cross-validation strategy\n",
    "    strat_kfold = StratifiedKFold(n_splits=10) # TODO\n",
    "\n",
    "    # Grid search for the model \n",
    "    #\"f1_macro\": Calculates F1-score per class and takes the average, treating all classes equally.\n",
    "    #\"f1_weighted\": Calculates F1-score per class and takes a weighted average, considering class imbalance.\n",
    "    grid_search = GridSearchCV(model, params, scoring='f1', cv=strat_kfold, n_jobs=10) # n_jobs=10 uses 10 parallel processes. Speeds up the process \n",
    "\n",
    "\n",
    "    if isinstance(model, RandomForestClassifier) or isinstance(model, SVC):\n",
    "        grid_search.fit(X_train_scaled, y_train.values.ravel())\n",
    "    else:\n",
    "        grid_search.fit(X_train, y_train)\n",
    "    best_param = grid_search.best_params_\n",
    "    best_score = grid_search.best_score_ \n",
    "    print(\"Best parameters are:\", best_param)\n",
    "    print(\"Best score is:\", best_score)\n",
    "\n",
    "    # Return the fitted grid search objects\n",
    "    # return grid_search, best_param, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training(model, X_train_scaled, y_train, X_validation_scaled, y_validation):\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_validation_scaled)\n",
    "    validation_f1 = f1_score(y_validation, y_pred)\n",
    "    print(\"Validation f1 score:\", validation_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_summary(y_train, y_train_pred, y_validation, y_validation_pred):\n",
    "    train_f1 = f1_score(y_train, y_train_pred) \n",
    "    validation_f1 = f1_score(y_validation, y_validation_pred) \n",
    "    print(\"Train f1 score:\", train_f1)\n",
    "\n",
    "    print(\"Validation f1 score:\", validation_f1)\n",
    "    print(\"\\nTraining Set Classification Report:\")\n",
    "\n",
    "    print(classification_report(y_train, y_train_pred))\n",
    "\n",
    "    print(\"Training Set Confusion Matrix:\")\n",
    "\n",
    "    print(confusion_matrix(y_train, y_train_pred))\n",
    "\n",
    "    print(\"\\nValidation Set Classification Report:\")\n",
    "\n",
    "    print(classification_report(y_validation, y_validation_pred))\n",
    "\n",
    "    print(\"Validation Set Confusion Matrix:\")\n",
    "\n",
    "    print(confusion_matrix(y_validation, y_validation_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_summary_one( y_validation, y_validation_pred):\n",
    "    validation_f1 = f1_score(y_validation, y_validation_pred) \n",
    "    print(\"Validation f1 score:\", validation_f1)\n",
    "    print(\"\\nValidation Set Classification Report:\")\n",
    "\n",
    "    print(classification_report(y_validation, y_validation_pred))\n",
    "\n",
    "    print(\"Validation Set Confusion Matrix:\")\n",
    "\n",
    "    print(confusion_matrix(y_validation, y_validation_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kaggle_submission(model, X_testing_scaled, x_testing_id):\n",
    "    y_pred = model.predict(X_testing_scaled)\n",
    "    y_pred = pd.DataFrame({\n",
    "        'index': x_testing_id , \n",
    "        'Diabetes_binary': y_pred,\n",
    "    })\n",
    "\n",
    "    # Save the predictions to a CSV file\n",
    "    y_pred.to_csv(f'./{model}_y_pred.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submission_pred(model, X_testing_scaled):\n",
    "    return model.predict(X_testing_scaled)\n",
    "\n",
    "\n",
    "def submission_proba(model, X_testing_scaled):\n",
    "    return model.predict_proba(X_testing_scaled)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search for  RandomForestClassifier(class_weight='balanced', max_depth=20,\n",
      "                       max_leaf_nodes=200, min_samples_leaf=20,\n",
      "                       n_estimators=500, random_state=42)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[236], line 16\u001b[0m\n\u001b[0;32m      5\u001b[0m cls_randomforest \u001b[38;5;241m=\u001b[39m RandomForestClassifier(class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m      6\u001b[0m                                           random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, \n\u001b[0;32m      7\u001b[0m                                           max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, \n\u001b[0;32m      8\u001b[0m                                           max_leaf_nodes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m, \n\u001b[0;32m      9\u001b[0m                                           min_samples_leaf\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m)\n\u001b[0;32m     11\u001b[0m param_grid_random_forest \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m300\u001b[39m, \u001b[38;5;241m400\u001b[39m, \u001b[38;5;241m500\u001b[39m],\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m30\u001b[39m],\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbootstrap\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m],\n\u001b[0;32m     15\u001b[0m }\n\u001b[1;32m---> 16\u001b[0m \u001b[43mperform_grid_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcls_randomforest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mparam_grid_random_forest\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[230], line 15\u001b[0m, in \u001b[0;36mperform_grid_search\u001b[1;34m(model, X_train_scaled, y_train, params)\u001b[0m\n\u001b[0;32m     11\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(model, params, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m'\u001b[39m, cv\u001b[38;5;241m=\u001b[39mstrat_kfold, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m) \u001b[38;5;66;03m# n_jobs=10 uses 10 parallel processes. Speeds up the process \u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, RandomForestClassifier) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, SVC):\n\u001b[1;32m---> 15\u001b[0m     \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     grid_search\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
      "File \u001b[1;32mc:\\Users\\sidne\\anaconda3\\envs\\algo\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sidne\\anaconda3\\envs\\algo\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1019\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1013\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1014\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1015\u001b[0m     )\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1019\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1022\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1023\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\sidne\\anaconda3\\envs\\algo\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1573\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1571\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1572\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1573\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sidne\\anaconda3\\envs\\algo\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:965\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    958\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    959\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    960\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    961\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    962\u001b[0m         )\n\u001b[0;32m    963\u001b[0m     )\n\u001b[1;32m--> 965\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    981\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    984\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    985\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    986\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    987\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    988\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\sidne\\anaconda3\\envs\\algo\\Lib\\site-packages\\sklearn\\utils\\parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     73\u001b[0m )\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sidne\\anaconda3\\envs\\algo\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sidne\\anaconda3\\envs\\algo\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sidne\\anaconda3\\envs\\algo\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "############### TESTING ####################\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "cls_randomforest = RandomForestClassifier(class_weight='balanced', \n",
    "                                          random_state=42, \n",
    "                                          max_depth=20, \n",
    "                                          max_leaf_nodes=200, \n",
    "                                          min_samples_leaf=20, n_estimators=500)\n",
    "\n",
    "param_grid_random_forest = {\n",
    "    'n_estimators': [10, 200, 300, 400, 500],\n",
    "    'max_depth': [20, 30],\n",
    "    'bootstrap': [True, False],\n",
    "}\n",
    "perform_grid_search(cls_randomforest, X_train_scaled, y_train, params= param_grid_random_forest)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sidne\\anaconda3\\envs\\algo\\Lib\\site-packages\\sklearn\\base.py:1473: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation f1 score: 0.4530521642619312\n"
     ]
    }
   ],
   "source": [
    "if is_equal_classes:\n",
    "    print('Equal classes')\n",
    "    cls_randomforest = RandomForestClassifier( class_weight='balanced',\n",
    "                                          random_state=42, \n",
    "                                          max_depth=20, \n",
    "                                          max_leaf_nodes=200, \n",
    "                                           n_estimators=1000) #min_samples_leaf=20\n",
    "else:\n",
    "    cls_randomforest = RandomForestClassifier( class_weight={0: 1, 1: 5}, # class_weight='balanced',\n",
    "                                            random_state=42, \n",
    "                                            max_depth=20, \n",
    "                                            max_leaf_nodes=200, \n",
    "                                            n_estimators=1000) #min_samples_leaf=20\n",
    "\n",
    "model_training(cls_randomforest, X_train_scaled, y_train, X_validation_scaled, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = predict_in_batches(cls_randomforest, X_train_scaled)\n",
    "y_validation_pred = predict_in_batches(cls_randomforest, X_validation_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_summary(y_train, y_train_pred, y_validation, y_validation_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "cls_decision_tree = DecisionTreeClassifier(max_depth=5)\n",
    "\n",
    "\n",
    "param_grid_decision_tree = {\n",
    "    'criterion': ['gini','entropy'],\n",
    "    'max_depth': [10, 20, 50],\n",
    "    'min_samples_leaf': [2, 3, 10],\n",
    "    'max_leaf_nodes': [5, 10, 50]\n",
    "}\n",
    "\n",
    "perform_grid_search(cls_decision_tree, X_train_scaled, y_train, params=param_grid_decision_tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation f1 score: 0.27153361344537813\n"
     ]
    }
   ],
   "source": [
    "cls_decision_tree = DecisionTreeClassifier(criterion='gini',max_depth=10, min_samples_leaf=2, max_leaf_nodes=10)\n",
    "model_training(cls_decision_tree, X_train_scaled, y_train, X_validation_scaled, y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree with Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sidne\\anaconda3\\envs\\algo\\Lib\\site-packages\\sklearn\\ensemble\\_bagging.py:888: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation f1 score: 0.4098209340963633\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "cls_decision_tree = DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=10, min_samples_leaf=2, max_leaf_nodes=10)\n",
    "bagging_model = BaggingClassifier(estimator=cls_decision_tree, n_estimators=50, random_state=42)\n",
    "model_training(bagging_model, X_train_scaled, y_train, X_validation_scaled, y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree with Adaboosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sidne\\anaconda3\\envs\\algo\\Lib\\site-packages\\sklearn\\utils\\validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\sidne\\anaconda3\\envs\\algo\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation f1 score: 0.4420583468395462\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Set up a decision stump as the weak learner\n",
    "base_estimator = DecisionTreeClassifier(max_depth=1, class_weight='balanced')  # Decision stump\n",
    "\n",
    "# Create an AdaBoost classifier using the decision tree as the base estimator\n",
    "ada_boost = AdaBoostClassifier(estimator=base_estimator, n_estimators=50, learning_rate=1.0, random_state=42)\n",
    "\n",
    "# Assuming `model_training` is a function that trains and evaluates the model\n",
    "model_training(ada_boost, X_train_scaled, y_train, X_validation_scaled, y_validation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_logistic = LogisticRegression(random_state=42, class_weight='balanced', max_iter=1000, dual=False, C=5)\n",
    "param_grid_logistic = {\n",
    "    'max_iter':[1000, 2000, 3000],\n",
    "    'tol': [1e-3, 1e-4, 1e-5],\n",
    "    'C': [0.5, 1, 10],\n",
    "}\n",
    "perform_grid_search(cls_logistic, X_train_scaled, y_train, param_grid_logistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sidne\\anaconda3\\envs\\algo\\Lib\\site-packages\\sklearn\\utils\\validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation f1 score: 0.45665197242002936\n"
     ]
    }
   ],
   "source": [
    "### Use best parameters to train the model\n",
    "if is_equal_classes:\n",
    "    print('Equal classes')\n",
    "    cls_logistic = LogisticRegression(random_state=42, class_weight='balanced', max_iter=1000, dual=False, C=1, tol=1e-3)\n",
    "else:\n",
    "    cls_logistic = LogisticRegression(random_state=42, class_weight={0: 1, 1: 5}, max_iter=1000, dual=False, C=1, tol=1e-3)\n",
    "model_training(cls_logistic, X_train_scaled, y_train, X_validation_scaled, y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the XGBoost classifier\n",
    "# booster [default= gbtree ]\n",
    "# Which booster to use. Can be gbtree, gblinear or dart; gbtree and dart use tree based models while gblinear uses linear functions.\n",
    "xgb_model = XGBClassifier(random_state=42, objective='binary:logistic', eval_metric='logloss') # binary:hinge\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'booster': ['gbtree', 'gblinear', 'dart'],\n",
    "    'eval_metric': ['error'],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "perform_grid_search(xgb_model, X_train_scaled, y_train, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation f1 score: 0.2989646246764452\n"
     ]
    }
   ],
   "source": [
    "xgb_model = XGBClassifier(random_state=42, objective='binary:logistic', eval_metric='error', booster='gbtree', n_estimators=5000, subsample=0.8)\n",
    "model_training(xgb_model, X_train_scaled, y_train, X_validation_scaled, y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation f1 score: 0.4536379769299024\n",
      "\n",
      "Validation Set Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.76      0.84     17460\n",
      "           1       0.33      0.72      0.45      2835\n",
      "\n",
      "    accuracy                           0.76     20295\n",
      "   macro avg       0.64      0.74      0.65     20295\n",
      "weighted avg       0.86      0.76      0.79     20295\n",
      "\n",
      "Validation Set Confusion Matrix:\n",
      "[[13324  4136]\n",
      " [  790  2045]]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the testing or validation data\n",
    "pred_array = []\n",
    "for model in [cls_randomforest, cls_logistic, xgb_model, bagging_model, ada_boost]:\n",
    "    pred_array.append(submission_pred(model, X_validation_scaled))\n",
    "\n",
    "# Take the majority vote\n",
    "pred_array = np.array(pred_array)\n",
    "for i in range(len(pred_array[0])):\n",
    "    if sum([pred[i] for pred in pred_array]) >= pred_array.shape[0] / 2:\n",
    "        pred_array[0][i] = 1#\n",
    "    else:\n",
    "        pred_array[0][i] = 0\n",
    "\n",
    "classification_summary_one(y_validation, pred_array[0])\n",
    "# Save the predictions to a CSV file\n",
    "# y_pred = pd.DataFrame({\n",
    "#     'index': x_testing_id , \n",
    "#     'Diabetes_binary': pred_array[0],\n",
    "# })\n",
    "# y_pred.to_csv('./y_pred.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation f1 score: 0.45218209622397365\n",
      "\n",
      "Validation Set Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.79      0.85     17460\n",
      "           1       0.34      0.68      0.45      2835\n",
      "\n",
      "    accuracy                           0.77     20295\n",
      "   macro avg       0.64      0.73      0.65     20295\n",
      "weighted avg       0.85      0.77      0.80     20295\n",
      "\n",
      "Validation Set Confusion Matrix:\n",
      "[[13716  3744]\n",
      " [  913  1922]]\n"
     ]
    }
   ],
   "source": [
    "prob_array = []\n",
    "for model in [cls_randomforest, cls_logistic, xgb_model, bagging_model, ada_boost]:\n",
    "    prob_array.append(submission_proba(model, X_validation_scaled))\n",
    "\n",
    "# Take most confident prediction\n",
    "prob_array = np.array(prob_array)\n",
    "for i in range(len(prob_array[0])):\n",
    "    if sum([prob[i] for prob in prob_array]) >= 2.3: # best is either 1.3 or 1.4 considering 3 models\n",
    "        prob_array[0][i] = 1\n",
    "    else:\n",
    "        prob_array[0][i] = 0\n",
    "pred_array = prob_array[0].astype(int)\n",
    "classification_summary_one(y_validation, pred_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary of model name and their trained model\n",
    "trained_models = {\n",
    "        'Decision Tree': cls_decision_tree,\n",
    "        'Random Forest': cls_randomforest,\n",
    "        'SVM': cls_svm }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict labels and calculate accuracy and F1score\n",
    "y_train_pred_dict, y_test_pred_dict, evaluation_results = eval_model(trained_models, X_train_scaled, X_validation_scaled, y_train, y_validation)\n",
    "\n",
    "# classification report and calculate confusion matrix\n",
    "report_model(y_train, y_validation, y_train_pred_dict, y_test_pred_dict, trained_models)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "algo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
